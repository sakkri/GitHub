{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakkri/GitHub/blob/main/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "967d6d35-87b7-4d2e-8c7c-2d6ffc409625",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "73b9c4a7-97bc-40ef-de8b-afbf308fb7de",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjv8XMPByO8o",
        "outputId": "7b64d3ed-6f18-4ba6-b4e0-9f2366f2501b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train,num_classes=10)\n",
        "y_test_cat = to_categorical(y_test,num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/225\n",
        "X_test_norm = X_test/225\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKyMFlL6yO8o",
        "outputId": "38e23a56-decf-4f13-b404-bf3de7b1e33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 1)         55        \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 1)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25)                0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               3120      \n",
            "                                                                 \n",
            " F5 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,249\n",
            "Trainable params: 14,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=1, name='C3',kernel_size=(3,3),activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120,activation='relu',name=\"C5\"))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84,activation='relu',name=\"F5\"))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "d4cbe5dc-fb3c-44c0-c07e-1472383d3b30",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 13s 23ms/step - loss: 2.1152 - accuracy: 0.3171 - val_loss: 1.6975 - val_accuracy: 0.5584\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2497 - accuracy: 0.5974 - val_loss: 1.0013 - val_accuracy: 0.6219\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.9068 - accuracy: 0.6550 - val_loss: 0.8782 - val_accuracy: 0.6645\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8243 - accuracy: 0.6903 - val_loss: 0.8221 - val_accuracy: 0.6880\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7789 - accuracy: 0.7091 - val_loss: 0.7878 - val_accuracy: 0.7021\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7533 - accuracy: 0.7187 - val_loss: 0.7635 - val_accuracy: 0.7211\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7321 - accuracy: 0.7287 - val_loss: 0.7527 - val_accuracy: 0.7051\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.7334 - val_loss: 0.7356 - val_accuracy: 0.7270\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7037 - accuracy: 0.7395 - val_loss: 0.7317 - val_accuracy: 0.7247\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6938 - accuracy: 0.7431 - val_loss: 0.7288 - val_accuracy: 0.7291\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.7474 - val_loss: 0.7052 - val_accuracy: 0.7373\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6710 - accuracy: 0.7510 - val_loss: 0.6974 - val_accuracy: 0.7473\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6610 - accuracy: 0.7557 - val_loss: 0.6893 - val_accuracy: 0.7475\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6588 - accuracy: 0.7533 - val_loss: 0.6777 - val_accuracy: 0.7494\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6447 - accuracy: 0.7615 - val_loss: 0.6744 - val_accuracy: 0.7537\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6387 - accuracy: 0.7637 - val_loss: 0.6614 - val_accuracy: 0.7557\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6260 - accuracy: 0.7681 - val_loss: 0.6536 - val_accuracy: 0.7572\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6162 - accuracy: 0.7716 - val_loss: 0.6454 - val_accuracy: 0.7650\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6119 - accuracy: 0.7731 - val_loss: 0.6359 - val_accuracy: 0.7673\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6016 - accuracy: 0.7775 - val_loss: 0.6287 - val_accuracy: 0.7681\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5917 - accuracy: 0.7815 - val_loss: 0.6198 - val_accuracy: 0.7708\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5888 - accuracy: 0.7819 - val_loss: 0.6132 - val_accuracy: 0.7703\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5798 - accuracy: 0.7861 - val_loss: 0.6144 - val_accuracy: 0.7726\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5741 - accuracy: 0.7875 - val_loss: 0.6077 - val_accuracy: 0.7755\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5664 - accuracy: 0.7909 - val_loss: 0.6004 - val_accuracy: 0.7792\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5624 - accuracy: 0.7923 - val_loss: 0.6056 - val_accuracy: 0.7729\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5565 - accuracy: 0.7942 - val_loss: 0.5942 - val_accuracy: 0.7824\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5574 - accuracy: 0.7932 - val_loss: 0.5847 - val_accuracy: 0.7824\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.7978 - val_loss: 0.5832 - val_accuracy: 0.7865\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5434 - accuracy: 0.7995 - val_loss: 0.5753 - val_accuracy: 0.7861\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5385 - accuracy: 0.8007 - val_loss: 0.5686 - val_accuracy: 0.7912\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5313 - accuracy: 0.8045 - val_loss: 0.5705 - val_accuracy: 0.7886\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5352 - accuracy: 0.8008 - val_loss: 0.5676 - val_accuracy: 0.7901\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5256 - accuracy: 0.8065 - val_loss: 0.5595 - val_accuracy: 0.7966\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5231 - accuracy: 0.8067 - val_loss: 0.5696 - val_accuracy: 0.7928\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5212 - accuracy: 0.8061 - val_loss: 0.5788 - val_accuracy: 0.7816\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5192 - accuracy: 0.8093 - val_loss: 0.5519 - val_accuracy: 0.7972\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5165 - accuracy: 0.8098 - val_loss: 0.5529 - val_accuracy: 0.7977\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5108 - accuracy: 0.8102 - val_loss: 0.5518 - val_accuracy: 0.7989\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5087 - accuracy: 0.8117 - val_loss: 0.5468 - val_accuracy: 0.8027\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5050 - accuracy: 0.8143 - val_loss: 0.5457 - val_accuracy: 0.8022\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5018 - accuracy: 0.8143 - val_loss: 0.5472 - val_accuracy: 0.8004\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4981 - accuracy: 0.8161 - val_loss: 0.5414 - val_accuracy: 0.8043\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4950 - accuracy: 0.8166 - val_loss: 0.5349 - val_accuracy: 0.8044\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4936 - accuracy: 0.8162 - val_loss: 0.5422 - val_accuracy: 0.8013\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4965 - accuracy: 0.8139 - val_loss: 0.5365 - val_accuracy: 0.8051\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4906 - accuracy: 0.8181 - val_loss: 0.5306 - val_accuracy: 0.8039\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4868 - accuracy: 0.8195 - val_loss: 0.5338 - val_accuracy: 0.8040\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4849 - accuracy: 0.8210 - val_loss: 0.5290 - val_accuracy: 0.8084\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4830 - accuracy: 0.8204 - val_loss: 0.5247 - val_accuracy: 0.8105\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4826 - accuracy: 0.8206 - val_loss: 0.5224 - val_accuracy: 0.8122\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4768 - accuracy: 0.8232 - val_loss: 0.5213 - val_accuracy: 0.8095\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4738 - accuracy: 0.8245 - val_loss: 0.5200 - val_accuracy: 0.8098\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4736 - accuracy: 0.8234 - val_loss: 0.5163 - val_accuracy: 0.8123\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4713 - accuracy: 0.8254 - val_loss: 0.5144 - val_accuracy: 0.8116\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4718 - accuracy: 0.8232 - val_loss: 0.5263 - val_accuracy: 0.8072\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4699 - accuracy: 0.8257 - val_loss: 0.5085 - val_accuracy: 0.8149\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4679 - accuracy: 0.8249 - val_loss: 0.5150 - val_accuracy: 0.8130\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4679 - accuracy: 0.8253 - val_loss: 0.5127 - val_accuracy: 0.8137\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.8255 - val_loss: 0.5116 - val_accuracy: 0.8127\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4619 - accuracy: 0.8282 - val_loss: 0.5105 - val_accuracy: 0.8150\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4611 - accuracy: 0.8291 - val_loss: 0.5070 - val_accuracy: 0.8138\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4589 - accuracy: 0.8288 - val_loss: 0.5119 - val_accuracy: 0.8130\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4599 - accuracy: 0.8293 - val_loss: 0.5072 - val_accuracy: 0.8137\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4608 - accuracy: 0.8278 - val_loss: 0.5087 - val_accuracy: 0.8149\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4600 - accuracy: 0.8276 - val_loss: 0.4999 - val_accuracy: 0.8146\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4542 - accuracy: 0.8316 - val_loss: 0.5077 - val_accuracy: 0.8107\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4567 - accuracy: 0.8301 - val_loss: 0.5022 - val_accuracy: 0.8190\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4505 - accuracy: 0.8324 - val_loss: 0.4955 - val_accuracy: 0.8194\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4499 - accuracy: 0.8318 - val_loss: 0.5031 - val_accuracy: 0.8159\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4482 - accuracy: 0.8338 - val_loss: 0.4946 - val_accuracy: 0.8225\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4478 - accuracy: 0.8329 - val_loss: 0.4944 - val_accuracy: 0.8192\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4475 - accuracy: 0.8327 - val_loss: 0.4908 - val_accuracy: 0.8189\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4466 - accuracy: 0.8347 - val_loss: 0.4950 - val_accuracy: 0.8169\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4454 - accuracy: 0.8342 - val_loss: 0.4930 - val_accuracy: 0.8195\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4424 - accuracy: 0.8354 - val_loss: 0.4886 - val_accuracy: 0.8224\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.8368 - val_loss: 0.4907 - val_accuracy: 0.8227\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4415 - accuracy: 0.8358 - val_loss: 0.4939 - val_accuracy: 0.8196\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4393 - accuracy: 0.8371 - val_loss: 0.4884 - val_accuracy: 0.8203\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4385 - accuracy: 0.8374 - val_loss: 0.4901 - val_accuracy: 0.8221\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4410 - accuracy: 0.8357 - val_loss: 0.4934 - val_accuracy: 0.8198\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.8378 - val_loss: 0.4832 - val_accuracy: 0.8233\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4386 - accuracy: 0.8365 - val_loss: 0.4885 - val_accuracy: 0.8234\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4348 - accuracy: 0.8387 - val_loss: 0.4845 - val_accuracy: 0.8229\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4360 - accuracy: 0.8380 - val_loss: 0.4812 - val_accuracy: 0.8241\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4335 - accuracy: 0.8392 - val_loss: 0.4852 - val_accuracy: 0.8227\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4326 - accuracy: 0.8399 - val_loss: 0.4879 - val_accuracy: 0.8221\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4336 - accuracy: 0.8392 - val_loss: 0.4810 - val_accuracy: 0.8246\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4316 - accuracy: 0.8396 - val_loss: 0.4805 - val_accuracy: 0.8213\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4284 - accuracy: 0.8418 - val_loss: 0.4852 - val_accuracy: 0.8243\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4323 - accuracy: 0.8400 - val_loss: 0.4779 - val_accuracy: 0.8282\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4291 - accuracy: 0.8402 - val_loss: 0.4868 - val_accuracy: 0.8221\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4285 - accuracy: 0.8408 - val_loss: 0.4799 - val_accuracy: 0.8222\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4294 - accuracy: 0.8413 - val_loss: 0.4799 - val_accuracy: 0.8217\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.8416 - val_loss: 0.4787 - val_accuracy: 0.8260\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.8434 - val_loss: 0.4782 - val_accuracy: 0.8269\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4256 - accuracy: 0.8411 - val_loss: 0.4732 - val_accuracy: 0.8281\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4216 - accuracy: 0.8443 - val_loss: 0.4814 - val_accuracy: 0.8249\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 0.8392 - val_loss: 0.4854 - val_accuracy: 0.8275\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4270 - accuracy: 0.8414 - val_loss: 0.4774 - val_accuracy: 0.8232\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa70066ec10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "6566e496-4c8c-4b94-d5b5-598ebd32b3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with CNN: 0.8445833333333334\n",
            "accuracy on test with CNN: 0.8232\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "2f689be7-36e9-42ca-f142-65d46d5f2885",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 2s 33ms/step - loss: 0.6417 - accuracy: 0.7879 - val_loss: 0.5189 - val_accuracy: 0.8056\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.4838 - accuracy: 0.8198 - val_loss: 0.5025 - val_accuracy: 0.8161\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4705 - accuracy: 0.8239 - val_loss: 0.4948 - val_accuracy: 0.8163\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.4609 - accuracy: 0.8277 - val_loss: 0.4871 - val_accuracy: 0.8169\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.4567 - accuracy: 0.8306 - val_loss: 0.4872 - val_accuracy: 0.8201\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4554 - accuracy: 0.8290 - val_loss: 0.4904 - val_accuracy: 0.8213\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.4506 - accuracy: 0.8307 - val_loss: 0.4934 - val_accuracy: 0.8120\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4505 - accuracy: 0.8318 - val_loss: 0.4863 - val_accuracy: 0.8188\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4473 - accuracy: 0.8319 - val_loss: 0.4784 - val_accuracy: 0.8232\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4441 - accuracy: 0.8336 - val_loss: 0.4864 - val_accuracy: 0.8158\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4435 - accuracy: 0.8338 - val_loss: 0.4875 - val_accuracy: 0.8202\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4401 - accuracy: 0.8359 - val_loss: 0.4801 - val_accuracy: 0.8201\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4372 - accuracy: 0.8357 - val_loss: 0.4813 - val_accuracy: 0.8195\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.4377 - accuracy: 0.8367 - val_loss: 0.4840 - val_accuracy: 0.8194\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4376 - accuracy: 0.8351 - val_loss: 0.4725 - val_accuracy: 0.8256\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4393 - accuracy: 0.8359 - val_loss: 0.4807 - val_accuracy: 0.8223\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4309 - accuracy: 0.8396 - val_loss: 0.4733 - val_accuracy: 0.8251\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4290 - accuracy: 0.8385 - val_loss: 0.4747 - val_accuracy: 0.8211\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4306 - accuracy: 0.8389 - val_loss: 0.4710 - val_accuracy: 0.8239\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4295 - accuracy: 0.8393 - val_loss: 0.4778 - val_accuracy: 0.8203\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4285 - accuracy: 0.8397 - val_loss: 0.4689 - val_accuracy: 0.8269\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.4271 - accuracy: 0.8396 - val_loss: 0.4795 - val_accuracy: 0.8197\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.4255 - accuracy: 0.8417 - val_loss: 0.4720 - val_accuracy: 0.8235\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4258 - accuracy: 0.8408 - val_loss: 0.4766 - val_accuracy: 0.8200\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4240 - accuracy: 0.8410 - val_loss: 0.4784 - val_accuracy: 0.8208\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4295 - accuracy: 0.8403 - val_loss: 0.4737 - val_accuracy: 0.8195\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4205 - accuracy: 0.8425 - val_loss: 0.4721 - val_accuracy: 0.8225\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4224 - accuracy: 0.8422 - val_loss: 0.4808 - val_accuracy: 0.8199\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4224 - accuracy: 0.8422 - val_loss: 0.4753 - val_accuracy: 0.8210\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4194 - accuracy: 0.8429 - val_loss: 0.4639 - val_accuracy: 0.8252\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4225 - accuracy: 0.8421 - val_loss: 0.4622 - val_accuracy: 0.8289\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.4176 - accuracy: 0.8430 - val_loss: 0.4663 - val_accuracy: 0.8249\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4161 - accuracy: 0.8441 - val_loss: 0.4704 - val_accuracy: 0.8203\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4179 - accuracy: 0.8419 - val_loss: 0.4710 - val_accuracy: 0.8259\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4142 - accuracy: 0.8442 - val_loss: 0.4658 - val_accuracy: 0.8232\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.4127 - accuracy: 0.8450 - val_loss: 0.4563 - val_accuracy: 0.8311\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.4125 - accuracy: 0.8445 - val_loss: 0.4658 - val_accuracy: 0.8292\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4142 - accuracy: 0.8439 - val_loss: 0.4693 - val_accuracy: 0.8253\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4105 - accuracy: 0.8465 - val_loss: 0.4602 - val_accuracy: 0.8294\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4103 - accuracy: 0.8461 - val_loss: 0.4716 - val_accuracy: 0.8220\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4099 - accuracy: 0.8469 - val_loss: 0.4774 - val_accuracy: 0.8235\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4125 - accuracy: 0.8441 - val_loss: 0.4649 - val_accuracy: 0.8251\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4100 - accuracy: 0.8457 - val_loss: 0.4549 - val_accuracy: 0.8308\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4091 - accuracy: 0.8459 - val_loss: 0.4720 - val_accuracy: 0.8211\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4122 - accuracy: 0.8435 - val_loss: 0.4616 - val_accuracy: 0.8287\n",
            "Epoch 46/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4091 - accuracy: 0.8446 - val_loss: 0.4640 - val_accuracy: 0.8254\n",
            "Epoch 47/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4060 - accuracy: 0.8462 - val_loss: 0.4635 - val_accuracy: 0.8294\n",
            "Epoch 48/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4046 - accuracy: 0.8476 - val_loss: 0.4594 - val_accuracy: 0.8256\n",
            "Epoch 49/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4035 - accuracy: 0.8475 - val_loss: 0.4566 - val_accuracy: 0.8320\n",
            "Epoch 50/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4056 - accuracy: 0.8474 - val_loss: 0.4550 - val_accuracy: 0.8298\n",
            "Epoch 51/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4014 - accuracy: 0.8490 - val_loss: 0.4574 - val_accuracy: 0.8310\n",
            "Epoch 52/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.4029 - accuracy: 0.8483 - val_loss: 0.4530 - val_accuracy: 0.8320\n",
            "Epoch 53/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4070 - accuracy: 0.8471 - val_loss: 0.4559 - val_accuracy: 0.8280\n",
            "Epoch 54/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.4034 - accuracy: 0.8488 - val_loss: 0.4592 - val_accuracy: 0.8262\n",
            "Epoch 55/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3990 - accuracy: 0.8508 - val_loss: 0.4505 - val_accuracy: 0.8307\n",
            "Epoch 56/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3982 - accuracy: 0.8513 - val_loss: 0.4506 - val_accuracy: 0.8339\n",
            "Epoch 57/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4010 - accuracy: 0.8492 - val_loss: 0.4608 - val_accuracy: 0.8295\n",
            "Epoch 58/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4002 - accuracy: 0.8488 - val_loss: 0.4557 - val_accuracy: 0.8316\n",
            "Epoch 59/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.3989 - accuracy: 0.8475 - val_loss: 0.4582 - val_accuracy: 0.8270\n",
            "Epoch 60/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.3974 - accuracy: 0.8504 - val_loss: 0.4532 - val_accuracy: 0.8328\n",
            "Epoch 61/100\n",
            "58/58 [==============================] - 2s 40ms/step - loss: 0.3995 - accuracy: 0.8493 - val_loss: 0.4468 - val_accuracy: 0.8347\n",
            "Epoch 62/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.4011 - accuracy: 0.8496 - val_loss: 0.4594 - val_accuracy: 0.8269\n",
            "Epoch 63/100\n",
            "58/58 [==============================] - 2s 28ms/step - loss: 0.3972 - accuracy: 0.8502 - val_loss: 0.4484 - val_accuracy: 0.8344\n",
            "Epoch 64/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3963 - accuracy: 0.8501 - val_loss: 0.4479 - val_accuracy: 0.8342\n",
            "Epoch 65/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3948 - accuracy: 0.8503 - val_loss: 0.4497 - val_accuracy: 0.8309\n",
            "Epoch 66/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3940 - accuracy: 0.8513 - val_loss: 0.4608 - val_accuracy: 0.8305\n",
            "Epoch 67/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.3979 - accuracy: 0.8507 - val_loss: 0.4486 - val_accuracy: 0.8331\n",
            "Epoch 68/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3966 - accuracy: 0.8509 - val_loss: 0.4561 - val_accuracy: 0.8318\n",
            "Epoch 69/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.3936 - accuracy: 0.8515 - val_loss: 0.4449 - val_accuracy: 0.8347\n",
            "Epoch 70/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3911 - accuracy: 0.8523 - val_loss: 0.4446 - val_accuracy: 0.8353\n",
            "Epoch 71/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3933 - accuracy: 0.8504 - val_loss: 0.4482 - val_accuracy: 0.8335\n",
            "Epoch 72/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3929 - accuracy: 0.8515 - val_loss: 0.4453 - val_accuracy: 0.8360\n",
            "Epoch 73/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3947 - accuracy: 0.8509 - val_loss: 0.4471 - val_accuracy: 0.8311\n",
            "Epoch 74/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3928 - accuracy: 0.8511 - val_loss: 0.4389 - val_accuracy: 0.8354\n",
            "Epoch 75/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3903 - accuracy: 0.8522 - val_loss: 0.4451 - val_accuracy: 0.8376\n",
            "Epoch 76/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3920 - accuracy: 0.8527 - val_loss: 0.4474 - val_accuracy: 0.8342\n",
            "Epoch 77/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.3930 - accuracy: 0.8501 - val_loss: 0.4471 - val_accuracy: 0.8320\n",
            "Epoch 78/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3893 - accuracy: 0.8533 - val_loss: 0.4387 - val_accuracy: 0.8386\n",
            "Epoch 79/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3896 - accuracy: 0.8535 - val_loss: 0.4401 - val_accuracy: 0.8378\n",
            "Epoch 80/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.3885 - accuracy: 0.8533 - val_loss: 0.4445 - val_accuracy: 0.8355\n",
            "Epoch 81/100\n",
            "58/58 [==============================] - 2s 29ms/step - loss: 0.3893 - accuracy: 0.8525 - val_loss: 0.4595 - val_accuracy: 0.8259\n",
            "Epoch 82/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3908 - accuracy: 0.8519 - val_loss: 0.4409 - val_accuracy: 0.8355\n",
            "Epoch 83/100\n",
            "58/58 [==============================] - 2s 41ms/step - loss: 0.3879 - accuracy: 0.8523 - val_loss: 0.4454 - val_accuracy: 0.8349\n",
            "Epoch 84/100\n",
            "58/58 [==============================] - 2s 39ms/step - loss: 0.3880 - accuracy: 0.8527 - val_loss: 0.4515 - val_accuracy: 0.8316\n",
            "Epoch 85/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3900 - accuracy: 0.8523 - val_loss: 0.4419 - val_accuracy: 0.8377\n",
            "Epoch 86/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.3858 - accuracy: 0.8536 - val_loss: 0.4443 - val_accuracy: 0.8332\n",
            "Epoch 87/100\n",
            "58/58 [==============================] - 2s 30ms/step - loss: 0.3861 - accuracy: 0.8537 - val_loss: 0.4472 - val_accuracy: 0.8340\n",
            "Epoch 88/100\n",
            "58/58 [==============================] - 2s 31ms/step - loss: 0.3871 - accuracy: 0.8529 - val_loss: 0.4414 - val_accuracy: 0.8359\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa715b95f10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "94012a89-d7ce-4f37-d334-a2073e525288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with CNN: 0.8530166666666666\n",
            "accuracy on test with CNN: 0.8359\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}